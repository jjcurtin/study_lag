{
  "hash": "5baddb97b38fb1219a10c7d59358c84d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Group by Time Effects\"\nauthor: \"Kendra Wyant\"\ndate: \"2025-01-27\"\noutput: \n  html_document:\n    toc: true \n    toc_depth: 4\nformat:\n  html:\n    embed-resources: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n### Set Up Environment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\n# handle conflicts\noptions(conflicts.policy = \"depends.ok\")\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"77e91675366f10788c6bcb59fa1cfc9ee0c75281\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\ntidymodels_conflictRules()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(tidymodels))\nsuppressPackageStartupMessages(library(tidyposterior))\nlibrary(kableExtra, exclude = \"group_rows\")\nlibrary(Rcpp, exclude = \"populate\")\nlibrary(brms, exclude = c(\"ar\", \"mixture\"))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading 'brms' package (version 2.22.0). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\ntheme_set(theme_classic()) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| output: false\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"a58e57da996d1b70bb9a5b58241325d6fd78890f\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| output: false\n\n# CHTC support functions\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/chtc/static_files/fun_chtc.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"6e9288d22f09da9ec15a1d5c046a0b6736ecce8b\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npath_processed <- format_path(str_c(\"studydata/risk/data_processed/lag\"))\npath_models_lag <- format_path(str_c(\"studydata/risk/models/lag\"))\n```\n:::\n\n\n\n\n### Read in Model Performance Metrics\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nauroc_dem_0 <- read_csv(here::here(path_models_lag, \n                                   \"test_auroc_6_x_5_1day_0_v3_nested_dem.csv\"),\n                      col_types = cols()) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  mutate(across(everything(), ~if_else(.x == 0, .0000001, .x))) |> \n  select(-outer_split_num)\n\n\nauroc_dem_24 <- read_csv(here::here(path_models_lag, \n                                    \"test_auroc_6_x_5_1day_24_v3_nested_dem.csv\"),\n                      col_types = cols())  |> \n  mutate(across(everything(), ~if_else(.x == 0, .0000001, .x))) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-outer_split_num)\n\nauroc_dem_72 <- read_csv(here::here(path_models_lag, \n                                    \"test_auroc_6_x_5_1day_72_v3_nested_dem.csv\"),\n                      col_types = cols()) |> \n  mutate(across(everything(), ~if_else(.x == 0, .0000001, .x))) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-outer_split_num)\n\nauroc_dem_168 <- read_csv(here::here(path_models_lag, \n                                     \"test_auroc_6_x_5_1day_168_v3_nested_dem.csv\"),\n                      col_types = cols())  |> \n  mutate(across(everything(), ~if_else(.x == 0, .0000001, .x))) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-outer_split_num)\n\nauroc_dem_336 <- read_csv(here::here(path_models_lag, \n                                     \"test_auroc_6_x_5_1day_336_v3_nested_dem.csv\"),\n                      col_types = cols())  |> \n  add_row(outer_split_num = 12) |>\n  add_row(outer_split_num = 28) |>\n  arrange(outer_split_num) |>\n  mutate(across(everything(), ~if_else(.x == 0, .0000001, .x))) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-outer_split_num)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nauroc_dem_all <- auroc_dem_0 |> \n  mutate(lag = 0) |> \n  bind_rows(auroc_dem_24 |> \n              mutate(lag = 24)) |>\n  bind_rows(auroc_dem_72 |> \n              mutate(lag = 72)) |>\n  bind_rows(auroc_dem_168 |> \n              mutate(lag = 168)) |>\n  bind_rows(auroc_dem_336 |> \n              mutate(lag = 336))\n\nset.seed(101)\n```\n:::\n\n\n\n### Race\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndata <- auroc_dem_all |> \n  select(id = fold_num, id2 = repeat_num, `not white`, `non-hispanic white` = white, lag) |> \n  pivot_longer(cols = c(`not white`, `non-hispanic white`), names_to = \"race\", values_to = \"auroc\") |> \n  mutate(race = factor(race)) |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 300\nColumns: 5\n$ id    <dbl> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1…\n$ id2   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3…\n$ lag   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ race  <fct> not white, non-hispanic white, not white, non-hispanic white, no…\n$ auroc <dbl> 0.9540139, 0.8926833, 0.3760259, 0.9203346, 0.7861969, 0.8664982…\n```\n\n\n:::\n:::\n\n\n\n\n\nSet priors to `perf_mod()` defaults\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npriors <- c(\n  prior(normal(2, 1.1), class = \"Intercept\"),\n  \n  prior(normal(0, 2.79), class = \"b\"),\n\n  prior(exponential(2.2), class = \"sigma\")\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmodel_race <- brm(\n  formula = auroc ~ 1 + race + lag + race*lag + (1 | id2/id), # folds nested in repeats\n  data = subset(data, !is.na(auroc)),\n  family = gaussian(link = \"logit\"), # normal distribution w/auroc bounded between 0 and 1\n  chains = 4,\n  prior = priors,\n  control = list(adapt_delta = 0.99), \n  iter = 6000,\n  thin = 10,\n  seed = 123\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000119 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.19 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 1: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 1: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 1: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 1: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 1: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 1: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 1: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 1: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 1: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 28.981 seconds (Warm-up)\nChain 1:                19.363 seconds (Sampling)\nChain 1:                48.344 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 4.3e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.43 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 2: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 2: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 2: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 2: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 2: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 2: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 2: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 2: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 2: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 2: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 2: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 30.253 seconds (Warm-up)\nChain 2:                17.955 seconds (Sampling)\nChain 2:                48.208 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 4.4e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.44 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 3: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 3: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 3: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 3: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 3: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 3: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 3: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 3: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 3: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 3: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 3: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 30.709 seconds (Warm-up)\nChain 3:                18.97 seconds (Sampling)\nChain 3:                49.679 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4.4e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.44 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 4: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 4: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 4: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 4: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 4: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 4: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 4: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 4: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 4: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 4: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 4: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 31.3 seconds (Warm-up)\nChain 4:                19.561 seconds (Sampling)\nChain 4:                50.861 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsummary(model_race) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = logit; sigma = identity \nFormula: auroc ~ 1 + race + lag + race * lag + (1 | id2/id) \n   Data: subset(data, !is.na(auroc)) (Number of observations: 280) \n  Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 10;\n         total post-warmup draws = 1200\n\nMultilevel Hyperparameters:\n~id2 (Number of levels: 6) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.22      0.20     0.01     0.76 1.00     1099     1059\n\n~id2:id (Number of levels: 30) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.88      0.14     0.65     1.19 1.00     1143     1143\n\nRegression Coefficients:\n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept            3.19      0.29     2.64     3.80 1.00     1190     1061\nracenotwhite        -2.18      0.22    -2.62    -1.79 1.00     1203     1200\nlag                 -0.00      0.00    -0.00    -0.00 1.00     1119     1165\nracenotwhite:lag     0.00      0.00     0.00     0.00 1.00     1160     1165\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.09      0.00     0.08     0.10 1.00     1111     1050\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_race <- summary(model_race)$fixed |>\n  as_tibble(rownames = \"coef\") |> \n  select(coef,\n         pp_mean = Estimate, \n         pp_lower = `l-95% CI`, \n         pp_upper = `u-95% CI`) \n```\n:::\n\n\n\n\n\nplot posterior distribution for race effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_race, variable = \"b_racenotwhite\") |> \n  as_tibble() |> \n  ggplot(aes(x = b_racenotwhite)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n  geom_segment(mapping = aes(y = 250, yend = 300, x = pp_mean, xend = pp_mean),\n               data = subset(pp_race, coef == \"racenotwhite\")) +\n  geom_segment(mapping = aes(y = 275, yend = 275, x = pp_lower, xend = pp_upper),\n                data = subset(pp_race, coef == \"racenotwhite\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\nplot posterior distribution for interaction effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_race, variable = \"b_racenotwhite:lag\") |> \n  ggplot(aes(x = `b_racenotwhite:lag`)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n    geom_segment(mapping = aes(y = 100, yend = 150, x = pp_mean, xend = pp_mean),\n               data = subset(pp_race, coef == \"racenotwhite:lag\")) +\n  geom_segment(mapping = aes(y = 125, yend = 125, x = pp_lower, xend = pp_upper),\n                data = subset(pp_race, coef == \"racenotwhite:lag\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\nCheck convergence diagnostics\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_trace(model_race, pars = c(\"b_Intercept\", \"b_racenotwhite\", \"b_lag\", \"b_racenotwhite:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_acf(model_race, pars = c(\"b_Intercept\", \"b_racenotwhite\", \"b_lag\", \"b_racenotwhite:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_dens(model_race, pars = c(\"b_Intercept\", \"b_racenotwhite\", \"b_lag\", \"b_racenotwhite:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-10-3.png){width=672}\n:::\n:::\n\n\n\nCheck posteriors\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_check(model_race)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\n### Sex\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndata <- auroc_dem_all |> \n  select(id = fold_num, id2 = repeat_num, female, male, lag) |> \n  pivot_longer(cols = c(female, male), names_to = \"sex\", values_to = \"auroc\") |>\n  mutate(sex = factor(sex, levels = c(\"male\", \"female\"))) |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 300\nColumns: 5\n$ id    <dbl> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1…\n$ id2   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3…\n$ lag   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ sex   <fct> female, male, female, male, female, male, female, male, female, …\n$ auroc <dbl> 0.8533697, 0.9353514, 0.8004071, 0.9713206, 0.8541759, 0.8814394…\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nmodel_sex <-brm(\n  formula = auroc ~ 1 + sex + lag + sex*lag + (1 | id2/id), # folds nested in repeats\n  data = subset(data, !is.na(auroc)),\n  family = gaussian(link = \"logit\"), # normal distribution w/auroc bounded between 0 and 1\n  chains = 4,\n  prior = priors,\n  control = list(adapt_delta = 0.99), \n  iter = 6000,\n  thin = 10,\n  seed = 123\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 9.8e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.98 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 1: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 1: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 1: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 1: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 1: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 1: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 1: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 1: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 1: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 52.927 seconds (Warm-up)\nChain 1:                23.973 seconds (Sampling)\nChain 1:                76.9 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 4.6e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.46 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 2: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 2: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 2: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 2: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 2: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 2: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 2: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 2: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 2: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 2: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 2: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 55.541 seconds (Warm-up)\nChain 2:                23.462 seconds (Sampling)\nChain 2:                79.003 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 4.7e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.47 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 3: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 3: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 3: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 3: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 3: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 3: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 3: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 3: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 3: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 3: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 3: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 53.659 seconds (Warm-up)\nChain 3:                18.305 seconds (Sampling)\nChain 3:                71.964 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4.8e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.48 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 4: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 4: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 4: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 4: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 4: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 4: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 4: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 4: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 4: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 4: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 4: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 53.515 seconds (Warm-up)\nChain 4:                18.248 seconds (Sampling)\nChain 4:                71.763 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsummary(model_sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = logit; sigma = identity \nFormula: auroc ~ 1 + sex + lag + sex * lag + (1 | id2/id) \n   Data: subset(data, !is.na(auroc)) (Number of observations: 296) \n  Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 10;\n         total post-warmup draws = 1200\n\nMultilevel Hyperparameters:\n~id2 (Number of levels: 6) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.07      0.07     0.00     0.24 1.00      997     1122\n\n~id2:id (Number of levels: 30) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.26      0.04     0.19     0.35 1.00     1098     1258\n\nRegression Coefficients:\n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept         2.29      0.08     2.14     2.44 1.00     1092     1097\nsexfemale        -0.48      0.05    -0.58    -0.37 1.00     1284     1211\nlag              -0.00      0.00    -0.00    -0.00 1.00     1228     1087\nsexfemale:lag    -0.00      0.00    -0.00    -0.00 1.00     1224     1007\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.04      0.00     0.03     0.04 1.00     1324     1191\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_sex <- summary(model_sex)$fixed |>\n  as_tibble(rownames = \"coef\") |> \n  select(coef,\n         pp_mean = Estimate, \n         pp_lower = `l-95% CI`, \n         pp_upper = `u-95% CI`) \n```\n:::\n\n\n\nplot posterior distribution for sex effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_sex, variable = \"b_sexfemale\") |> \n  as_tibble() |> \n  ggplot(aes(x = b_sexfemale)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n  geom_segment(mapping = aes(y = 300, yend = 350, x = pp_mean, xend = pp_mean),\n               data = subset(pp_sex, coef == \"sexfemale\")) +\n  geom_segment(mapping = aes(y = 325, yend = 325, x = pp_lower, xend = pp_upper),\n                data = subset(pp_sex, coef == \"sexfemale\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\nplot posterior distribution for interaction effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_sex, variable = \"b_sexfemale:lag\") |> \n  ggplot(aes(x = `b_sexfemale:lag`)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n    geom_segment(mapping = aes(y = 100, yend = 150, x = pp_mean, xend = pp_mean),\n               data = subset(pp_sex, coef == \"sexfemale:lag\")) +\n  geom_segment(mapping = aes(y = 125, yend = 125, x = pp_lower, xend = pp_upper),\n                data = subset(pp_sex, coef == \"sexfemale:lag\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_trace(model_sex, pars = c(\"b_Intercept\", \"b_sexfemale\", \"b_lag\", \"b_sexfemale:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_acf(model_sex, pars = c(\"b_Intercept\", \"b_sexfemale\", \"b_lag\", \"b_sexfemale:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-17-2.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_dens(model_sex, pars = c(\"b_Intercept\", \"b_sexfemale\", \"b_lag\", \"b_sexfemale:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-17-3.png){width=672}\n:::\n:::\n\n\n\nCheck posteriors\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_check(model_sex)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n### Income\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndata <- auroc_dem_all |> \n  select(id = fold_num, id2 = repeat_num, `above poverty`, `below poverty`, lag) |> \n  pivot_longer(cols = c(`above poverty`, `below poverty`), names_to = \"income\", \n               values_to = \"auroc\") |>\n  mutate(income = factor(income)) |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 300\nColumns: 5\n$ id     <dbl> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, …\n$ id2    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, …\n$ lag    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ income <fct> above poverty, below poverty, above poverty, below poverty, abo…\n$ auroc  <dbl> 0.8891591, NA, 0.9193512, 0.9155717, 0.8950993, 0.3825632, 0.90…\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nmodel_income <- brm(\n  formula = auroc ~ 1 + income + lag + income*lag + (1 | id2/id), # folds nested in repeats\n  data = subset(data, !is.na(auroc)),\n  family = gaussian(link = \"logit\"), # normal distribution w/auroc bounded between 0 and 1\n  chains = 4,\n  prior = priors,\n  control = list(adapt_delta = 0.999), \n  iter = 6000,\n  thin = 10,\n  seed = 123\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 9.9e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.99 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 1: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 1: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 1: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 1: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 1: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 1: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 1: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 1: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 1: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 58.831 seconds (Warm-up)\nChain 1:                54.148 seconds (Sampling)\nChain 1:                112.979 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 4.5e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 2: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 2: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 2: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 2: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 2: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 2: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 2: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 2: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 2: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 2: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 2: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 60.222 seconds (Warm-up)\nChain 2:                23.24 seconds (Sampling)\nChain 2:                83.462 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 4.5e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 3: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 3: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 3: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 3: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 3: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 3: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 3: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 3: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 3: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 3: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 3: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 62.62 seconds (Warm-up)\nChain 3:                72.447 seconds (Sampling)\nChain 3:                135.067 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4.5e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 4: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 4: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 4: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 4: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 4: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 4: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 4: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 4: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 4: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 4: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 4: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 64.845 seconds (Warm-up)\nChain 4:                42.014 seconds (Sampling)\nChain 4:                106.859 seconds (Total)\nChain 4: \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: There were 29 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See\nhttps://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Examine the pairs() plot to diagnose sampling problems\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsummary(model_income)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = logit; sigma = identity \nFormula: auroc ~ 1 + income + lag + income * lag + (1 | id2/id) \n   Data: subset(data, !is.na(auroc)) (Number of observations: 286) \n  Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 10;\n         total post-warmup draws = 1200\n\nMultilevel Hyperparameters:\n~id2 (Number of levels: 6) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.28      0.24     0.01     0.89 1.00     1017     1248\n\n~id2:id (Number of levels: 30) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.65      0.10     0.49     0.89 1.00     1160     1134\n\nRegression Coefficients:\n                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                  2.48      0.21     2.09     2.91 1.00     1249\nincomebelowpoverty        -1.05      0.10    -1.24    -0.85 1.00     1216\nlag                       -0.00      0.00    -0.00    -0.00 1.00     1052\nincomebelowpoverty:lag    -0.00      0.00    -0.00     0.00 1.00     1036\n                       Tail_ESS\nIntercept                  1174\nincomebelowpoverty         1256\nlag                        1128\nincomebelowpoverty:lag     1172\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.07      0.00     0.06     0.08 1.00     1251      941\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_income <- summary(model_income)$fixed |>\n  as_tibble(rownames = \"coef\") |> \n  select(coef,\n         pp_mean = Estimate, \n         pp_lower = `l-95% CI`, \n         pp_upper = `u-95% CI`) \n```\n:::\n\n\n\nplot posterior distribution for income effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_income, variable = \"b_incomebelowpoverty\") |> \n  as_tibble() |> \n  ggplot(aes(x = b_incomebelowpoverty)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n  geom_segment(mapping = aes(y = 225, yend = 275, x = pp_mean, xend = pp_mean),\n               data = subset(pp_income, coef == \"incomebelowpoverty\")) +\n  geom_segment(mapping = aes(y = 250, yend = 250, x = pp_lower, xend = pp_upper),\n                data = subset(pp_income, coef == \"incomebelowpoverty\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\n\nplot posterior distribution for interaction effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_income, variable = \"b_incomebelowpoverty:lag\") |> \n  ggplot(aes(x = `b_incomebelowpoverty:lag`)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n  geom_segment(mapping = aes(y = 125, yend = 175, x = pp_mean, xend = pp_mean),\n               data = subset(pp_income, coef == \"incomebelowpoverty:lag\")) +\n  geom_segment(mapping = aes(y = 150, yend = 150, x = pp_lower, xend = pp_upper),\n                data = subset(pp_income, coef == \"incomebelowpoverty:lag\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_trace(model_income, pars = c(\"b_Intercept\", \"b_incomebelowpoverty\", \"b_lag\", \"b_incomebelowpoverty:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_acf(model_income, pars = c(\"b_Intercept\", \"b_incomebelowpoverty\", \"b_lag\", \"b_incomebelowpoverty:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-24-2.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_dens(model_income, pars = c(\"b_Intercept\", \"b_incomebelowpoverty\", \"b_lag\", \"b_incomebelowpoverty:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-24-3.png){width=672}\n:::\n:::\n\n\n\nCheck posteriors\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_check(model_income)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::",
    "supporting": [
      "ana_time_subgroup_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}