{
  "hash": "65e7932a79a6ed38b25301560d272e21",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Group by Time Effects\"\nauthor: \"Kendra Wyant\"\ndate: \"2025-06-11\"\noutput: \n  html_document:\n    toc: true \n    toc_depth: 4\nformat:\n  html:\n    embed-resources: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n### Set Up Environment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\n# handle conflicts\noptions(conflicts.policy = \"depends.ok\")\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"32a0bc8ced92c79756b56ddcdc9a06e639795da6\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\ntidymodels_conflictRules()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(tidymodels))\nsuppressPackageStartupMessages(library(tidyposterior))\nlibrary(kableExtra, exclude = \"group_rows\")\nlibrary(Rcpp, exclude = \"populate\")\nlibrary(brms, exclude = c(\"ar\", \"mixture\"))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading 'brms' package (version 2.22.0). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\ntheme_set(theme_classic()) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| output: false\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"de12d764438078a9341db9bc0b2472c87e0ae846\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| output: false\n\n# CHTC support functions\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/chtc/static_files/fun_chtc.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"7be28854408fb58990ee996339c3258c133eed75\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npath_processed <- format_path(str_c(\"risk/data_processed/lag\"))\npath_models_lag <- format_path(str_c(\"risk/models/lag\"))\n```\n:::\n\n\n\n\n### Read in Model Performance Metrics\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nauroc_dem_0 <- read_csv(here::here(path_models_lag, \n                                   \"test_auroc_6_x_5_1day_0_v3_nested_strat_lh_fairness.csv\"),\n                      col_types = cols()) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  mutate(across(everything(), ~if_else(.x == 0, .0000001, .x))) |> \n  select(-outer_split_num)\n\n\nauroc_dem_24 <- read_csv(here::here(path_models_lag, \n                                    \"test_auroc_6_x_5_1day_24_v3_nested_strat_lh_fairness.csv\"),\n                      col_types = cols())  |> \n  mutate(across(everything(), ~if_else(.x == 0, .0000001, .x))) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-outer_split_num)\n\nauroc_dem_72 <- read_csv(here::here(path_models_lag, \n                                    \"test_auroc_6_x_5_1day_72_v3_nested_strat_lh_fairness.csv\"),\n                      col_types = cols()) |> \n  mutate(across(everything(), ~if_else(.x == 0, .0000001, .x))) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-outer_split_num)\n\nauroc_dem_168 <- read_csv(here::here(path_models_lag, \n                                     \"test_auroc_6_x_5_1day_168_v3_nested_strat_lh_fairness.csv\"),\n                      col_types = cols())  |> \n  mutate(across(everything(), ~if_else(.x == 0, .0000001, .x))) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-outer_split_num)\n\nauroc_dem_336 <- read_csv(here::here(path_models_lag, \n                                     \"test_auroc_6_x_5_1day_336_v3_nested_strat_lh_fairness.csv\"),\n                      col_types = cols())  |> \n  arrange(outer_split_num) |>\n  mutate(across(everything(), ~if_else(.x == 0, .0000001, .x))) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-outer_split_num)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nauroc_dem_all <- auroc_dem_0 |> \n  mutate(lag = 0) |> \n  bind_rows(auroc_dem_24 |> \n              mutate(lag = 24)) |>\n  bind_rows(auroc_dem_72 |> \n              mutate(lag = 72)) |>\n  bind_rows(auroc_dem_168 |> \n              mutate(lag = 168)) |>\n  bind_rows(auroc_dem_336 |> \n              mutate(lag = 336))\n\nset.seed(101)\n```\n:::\n\n\n\n### Race\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndata <- auroc_dem_all |> \n  select(id = fold_num, id2 = repeat_num, `not white`, `non-hispanic white` = white, lag) |> \n  pivot_longer(cols = c(`not white`, `non-hispanic white`), names_to = \"race\", values_to = \"auroc\") |> \n  mutate(race = factor(race)) |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 300\nColumns: 5\n$ id    <dbl> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1…\n$ id2   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3…\n$ lag   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ race  <fct> not white, non-hispanic white, not white, non-hispanic white, no…\n$ auroc <dbl> 0.8624530, 0.9032410, 0.8416644, 0.9328614, 0.9510940, 0.9253825…\n```\n\n\n:::\n:::\n\n\n\n\n\nSet priors to `perf_mod()` defaults\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npriors <- c(\n  prior(normal(2, 1.1), class = \"Intercept\"),\n  \n  prior(normal(0, 2.79), class = \"b\"),\n\n  prior(exponential(2.2), class = \"sigma\")\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmodel_race <- brm(\n  formula = auroc ~ 1 + race + lag + race*lag + (1 | id2/id), # folds nested in repeats\n  data = subset(data, !is.na(auroc)),\n  family = gaussian(link = \"logit\"), # normal distribution w/auroc bounded between 0 and 1\n  chains = 4,\n  prior = priors,\n  control = list(adapt_delta = 0.99), \n  iter = 6000,\n  thin = 10,\n  seed = 123\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000118 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.18 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 1: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 1: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 1: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 1: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 1: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 1: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 1: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 1: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 1: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 32.792 seconds (Warm-up)\nChain 1:                20.681 seconds (Sampling)\nChain 1:                53.473 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 4.9e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.49 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 2: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 2: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 2: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 2: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 2: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 2: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 2: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 2: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 2: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 2: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 2: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 34.777 seconds (Warm-up)\nChain 2:                19.518 seconds (Sampling)\nChain 2:                54.295 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 4.8e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.48 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 3: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 3: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 3: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 3: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 3: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 3: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 3: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 3: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 3: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 3: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 3: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 34.211 seconds (Warm-up)\nChain 3:                26.701 seconds (Sampling)\nChain 3:                60.912 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4.5e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 4: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 4: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 4: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 4: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 4: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 4: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 4: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 4: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 4: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 4: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 4: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 33.783 seconds (Warm-up)\nChain 4:                21.075 seconds (Sampling)\nChain 4:                54.858 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsummary(model_race) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = logit; sigma = identity \nFormula: auroc ~ 1 + race + lag + race * lag + (1 | id2/id) \n   Data: subset(data, !is.na(auroc)) (Number of observations: 293) \n  Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 10;\n         total post-warmup draws = 1200\n\nMultilevel Hyperparameters:\n~id2 (Number of levels: 6) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.34      0.30     0.01     1.11 1.00     1091     1121\n\n~id2:id (Number of levels: 30) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     1.21      0.20     0.88     1.65 1.00     1178     1151\n\nRegression Coefficients:\n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept            4.07      0.42     3.26     4.93 1.00     1189      991\nracenotwhite        -2.85      0.32    -3.58    -2.26 1.00     1390     1174\nlag                 -0.00      0.00    -0.00     0.00 1.00     1119     1128\nracenotwhite:lag     0.00      0.00    -0.00     0.00 1.00     1183     1133\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.10      0.00     0.09     0.10 1.00     1156      994\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_race <- summary(model_race)$fixed |>\n  as_tibble(rownames = \"coef\") |> \n  select(coef,\n         pp_mean = Estimate, \n         pp_lower = `l-95% CI`, \n         pp_upper = `u-95% CI`) \n```\n:::\n\n\n\n\n\nplot posterior distribution for race effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_race, variable = \"b_racenotwhite\") |> \n  as_tibble() |> \n  ggplot(aes(x = b_racenotwhite)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n  geom_segment(mapping = aes(y = 250, yend = 300, x = pp_mean, xend = pp_mean),\n               data = subset(pp_race, coef == \"racenotwhite\")) +\n  geom_segment(mapping = aes(y = 275, yend = 275, x = pp_lower, xend = pp_upper),\n                data = subset(pp_race, coef == \"racenotwhite\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\nplot posterior distribution for interaction effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_race, variable = \"b_racenotwhite:lag\") |> \n  ggplot(aes(x = `b_racenotwhite:lag`)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n    geom_segment(mapping = aes(y = 100, yend = 150, x = pp_mean, xend = pp_mean),\n               data = subset(pp_race, coef == \"racenotwhite:lag\")) +\n  geom_segment(mapping = aes(y = 125, yend = 125, x = pp_lower, xend = pp_upper),\n                data = subset(pp_race, coef == \"racenotwhite:lag\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\nCheck convergence diagnostics\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_trace(model_race, pars = c(\"b_Intercept\", \"b_racenotwhite\", \"b_lag\", \"b_racenotwhite:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_acf(model_race, pars = c(\"b_Intercept\", \"b_racenotwhite\", \"b_lag\", \"b_racenotwhite:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_dens(model_race, pars = c(\"b_Intercept\", \"b_racenotwhite\", \"b_lag\", \"b_racenotwhite:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-10-3.png){width=672}\n:::\n:::\n\n\n\nCheck posteriors\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_check(model_race)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\n### Sex\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndata <- auroc_dem_all |> \n  select(id = fold_num, id2 = repeat_num, female, male, lag) |> \n  pivot_longer(cols = c(female, male), names_to = \"sex\", values_to = \"auroc\") |>\n  mutate(sex = factor(sex, levels = c(\"male\", \"female\"))) |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 300\nColumns: 5\n$ id    <dbl> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1…\n$ id2   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3…\n$ lag   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ sex   <fct> female, male, female, male, female, male, female, male, female, …\n$ auroc <dbl> 0.9245708, 0.8477054, 0.8592244, 0.9544339, 0.9019895, 0.9756489…\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nmodel_sex <-brm(\n  formula = auroc ~ 1 + sex + lag + sex*lag + (1 | id2/id), # folds nested in repeats\n  data = subset(data, !is.na(auroc)),\n  family = gaussian(link = \"logit\"), # normal distribution w/auroc bounded between 0 and 1\n  chains = 4,\n  prior = priors,\n  control = list(adapt_delta = 0.99), \n  iter = 6000,\n  thin = 10,\n  seed = 123\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 9.6e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.96 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 1: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 1: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 1: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 1: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 1: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 1: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 1: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 1: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 1: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 56.009 seconds (Warm-up)\nChain 1:                30.636 seconds (Sampling)\nChain 1:                86.645 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 4.7e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.47 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 2: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 2: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 2: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 2: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 2: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 2: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 2: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 2: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 2: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 2: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 2: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 55.296 seconds (Warm-up)\nChain 2:                31.525 seconds (Sampling)\nChain 2:                86.821 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 4.7e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.47 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 3: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 3: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 3: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 3: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 3: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 3: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 3: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 3: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 3: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 3: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 3: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 56.773 seconds (Warm-up)\nChain 3:                19.058 seconds (Sampling)\nChain 3:                75.831 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4.5e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 4: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 4: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 4: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 4: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 4: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 4: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 4: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 4: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 4: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 4: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 4: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 58.012 seconds (Warm-up)\nChain 4:                34.722 seconds (Sampling)\nChain 4:                92.734 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsummary(model_sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = logit; sigma = identity \nFormula: auroc ~ 1 + sex + lag + sex * lag + (1 | id2/id) \n   Data: subset(data, !is.na(auroc)) (Number of observations: 300) \n  Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 10;\n         total post-warmup draws = 1200\n\nMultilevel Hyperparameters:\n~id2 (Number of levels: 6) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.08      0.08     0.00     0.31 1.00     1021     1086\n\n~id2:id (Number of levels: 30) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.34      0.06     0.25     0.46 1.00     1239     1065\n\nRegression Coefficients:\n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept         2.43      0.09     2.25     2.60 1.00     1092     1135\nsexfemale        -0.52      0.06    -0.63    -0.41 1.00     1252     1210\nlag              -0.00      0.00    -0.00    -0.00 1.00     1141      854\nsexfemale:lag    -0.00      0.00    -0.00    -0.00 1.01     1298     1190\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.03      0.00     0.03     0.04 1.00     1222     1216\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_sex <- summary(model_sex)$fixed |>\n  as_tibble(rownames = \"coef\") |> \n  select(coef,\n         pp_mean = Estimate, \n         pp_lower = `l-95% CI`, \n         pp_upper = `u-95% CI`) \n```\n:::\n\n\n\nplot posterior distribution for sex effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_sex, variable = \"b_sexfemale\") |> \n  as_tibble() |> \n  ggplot(aes(x = b_sexfemale)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n  geom_segment(mapping = aes(y = 300, yend = 350, x = pp_mean, xend = pp_mean),\n               data = subset(pp_sex, coef == \"sexfemale\")) +\n  geom_segment(mapping = aes(y = 325, yend = 325, x = pp_lower, xend = pp_upper),\n                data = subset(pp_sex, coef == \"sexfemale\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\nplot posterior distribution for interaction effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_sex, variable = \"b_sexfemale:lag\") |> \n  ggplot(aes(x = `b_sexfemale:lag`)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n    geom_segment(mapping = aes(y = 100, yend = 150, x = pp_mean, xend = pp_mean),\n               data = subset(pp_sex, coef == \"sexfemale:lag\")) +\n  geom_segment(mapping = aes(y = 125, yend = 125, x = pp_lower, xend = pp_upper),\n                data = subset(pp_sex, coef == \"sexfemale:lag\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_trace(model_sex, pars = c(\"b_Intercept\", \"b_sexfemale\", \"b_lag\", \"b_sexfemale:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_acf(model_sex, pars = c(\"b_Intercept\", \"b_sexfemale\", \"b_lag\", \"b_sexfemale:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-17-2.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_dens(model_sex, pars = c(\"b_Intercept\", \"b_sexfemale\", \"b_lag\", \"b_sexfemale:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-17-3.png){width=672}\n:::\n:::\n\n\n\nCheck posteriors\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_check(model_sex)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n### Income\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndata <- auroc_dem_all |> \n  select(id = fold_num, id2 = repeat_num, `above poverty`, `below poverty`, lag) |> \n  pivot_longer(cols = c(`above poverty`, `below poverty`), names_to = \"income\", \n               values_to = \"auroc\") |>\n  mutate(income = factor(income)) |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 300\nColumns: 5\n$ id     <dbl> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, …\n$ id2    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, …\n$ lag    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ income <fct> above poverty, below poverty, above poverty, below poverty, abo…\n$ auroc  <dbl> 0.8902036, 0.9093397, 0.9092639, 0.9241711, 0.9392897, 0.902794…\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nmodel_income <- brm(\n  formula = auroc ~ 1 + income + lag + income*lag + (1 | id2/id), # folds nested in repeats\n  data = subset(data, !is.na(auroc)),\n  family = gaussian(link = \"logit\"), # normal distribution w/auroc bounded between 0 and 1\n  chains = 4,\n  prior = priors,\n  control = list(adapt_delta = 0.999), \n  iter = 6000,\n  thin = 10,\n  seed = 123\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000103 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.03 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 1: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 1: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 1: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 1: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 1: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 1: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 1: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 1: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 1: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 74.53 seconds (Warm-up)\nChain 1:                40.795 seconds (Sampling)\nChain 1:                115.325 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 4.5e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 2: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 2: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 2: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 2: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 2: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 2: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 2: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 2: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 2: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 2: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 2: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 73.805 seconds (Warm-up)\nChain 2:                41.083 seconds (Sampling)\nChain 2:                114.888 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 4.5e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 3: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 3: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 3: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 3: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 3: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 3: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 3: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 3: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 3: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 3: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 3: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 71.174 seconds (Warm-up)\nChain 3:                40.105 seconds (Sampling)\nChain 3:                111.279 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4.5e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 4: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 4: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 4: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 4: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 4: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 4: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 4: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 4: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 4: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 4: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 4: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 74.949 seconds (Warm-up)\nChain 4:                45.556 seconds (Sampling)\nChain 4:                120.505 seconds (Total)\nChain 4: \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: There were 6 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See\nhttps://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Examine the pairs() plot to diagnose sampling problems\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsummary(model_income)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = logit; sigma = identity \nFormula: auroc ~ 1 + income + lag + income * lag + (1 | id2/id) \n   Data: subset(data, !is.na(auroc)) (Number of observations: 300) \n  Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 10;\n         total post-warmup draws = 1200\n\nMultilevel Hyperparameters:\n~id2 (Number of levels: 6) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.12      0.12     0.00     0.41 1.00     1071     1113\n\n~id2:id (Number of levels: 30) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.47      0.07     0.36     0.64 1.00     1080     1259\n\nRegression Coefficients:\n                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                  2.27      0.12     2.03     2.52 1.00     1218\nincomebelowpoverty        -0.37      0.07    -0.50    -0.25 1.00     1158\nlag                       -0.00      0.00    -0.00    -0.00 1.00     1129\nincomebelowpoverty:lag    -0.00      0.00    -0.00     0.00 1.00     1325\n                       Tail_ESS\nIntercept                  1116\nincomebelowpoverty         1132\nlag                        1214\nincomebelowpoverty:lag     1213\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.04      0.00     0.04     0.05 1.00     1015      854\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_income <- summary(model_income)$fixed |>\n  as_tibble(rownames = \"coef\") |> \n  select(coef,\n         pp_mean = Estimate, \n         pp_lower = `l-95% CI`, \n         pp_upper = `u-95% CI`) \n```\n:::\n\n\n\nplot posterior distribution for income effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_income, variable = \"b_incomebelowpoverty\") |> \n  as_tibble() |> \n  ggplot(aes(x = b_incomebelowpoverty)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n  geom_segment(mapping = aes(y = 225, yend = 275, x = pp_mean, xend = pp_mean),\n               data = subset(pp_income, coef == \"incomebelowpoverty\")) +\n  geom_segment(mapping = aes(y = 250, yend = 250, x = pp_lower, xend = pp_upper),\n                data = subset(pp_income, coef == \"incomebelowpoverty\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\n\nplot posterior distribution for interaction effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_income, variable = \"b_incomebelowpoverty:lag\") |> \n  ggplot(aes(x = `b_incomebelowpoverty:lag`)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n  geom_segment(mapping = aes(y = 125, yend = 175, x = pp_mean, xend = pp_mean),\n               data = subset(pp_income, coef == \"incomebelowpoverty:lag\")) +\n  geom_segment(mapping = aes(y = 150, yend = 150, x = pp_lower, xend = pp_upper),\n                data = subset(pp_income, coef == \"incomebelowpoverty:lag\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_trace(model_income, pars = c(\"b_Intercept\", \"b_incomebelowpoverty\", \"b_lag\", \"b_incomebelowpoverty:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_acf(model_income, pars = c(\"b_Intercept\", \"b_incomebelowpoverty\", \"b_lag\", \"b_incomebelowpoverty:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-24-2.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_dens(model_income, pars = c(\"b_Intercept\", \"b_incomebelowpoverty\", \"b_lag\", \"b_incomebelowpoverty:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-24-3.png){width=672}\n:::\n:::\n\n\n\nCheck posteriors\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_check(model_income)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::",
    "supporting": [
      "ana_time_subgroup_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}