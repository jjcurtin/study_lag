{
  "hash": "1b407f1a498f3caa93c784d51b8f41a9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Model evaluation\"\nauthor: \"Kendra Wyant\"\ndate: \"2025-01-27\"\noutput: \n  html_document:\n    toc: true \n    toc_depth: 4\nformat:\n  html:\n    embed-resources: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n### Set Up Environment\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(source(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\"))\nsuppressPackageStartupMessages(library(tidyposterior))\n\npath_models_lag <- format_path(str_c(\"studydata/risk/models/lag\"))\npath_shared <- format_path(\"studydata/risk/data_processed/shared\")\npath_processed <- format_path(\"studydata/risk/data_processed/lag\")\n\noptions(knitr.kable.NA = '')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntest_metrics_0 <- read_csv(here::here(path_models_lag, \n                                      \"test_auroc_3_x_10_1day_0_v3_nested_main.csv\"), \n                              col_types = cols()) |> \n  select(outer_split_num, \"lag0\" = roc_auc)\n\ntest_metrics_24 <- read_csv(here::here(path_models_lag, \n                                       \"test_auroc_3_x_10_1day_24_v3_nested_main.csv\"),\n                             col_types = cols()) |> \n  select(outer_split_num, \"lag24\" = roc_auc)\n\ntest_metrics_72 <- read_csv(here::here(path_models_lag, \n                                       \"test_auroc_3_x_10_1day_72_v3_nested_main.csv\"),\n                              col_types = cols()) |> \n  select(outer_split_num, \"lag72\" = roc_auc)\n\ntest_metrics_168 <- read_csv(here::here(path_models_lag, \n                                        \"test_auroc_3_x_10_1day_168_v3_nested_main.csv\"), \n                              col_types = cols()) |> \n  select(outer_split_num, \"lag168\" = roc_auc)\n\ntest_metrics_336 <- read_csv(here::here(path_models_lag, \n                                       \"test_auroc_3_x_10_1day_336_v3_nested_main.csv\"),\n                             col_types = cols()) |> \n  select(outer_split_num, \"lag336\" = roc_auc)\n\ntest_metrics_all <- test_metrics_0 |> \n  left_join(test_metrics_24, by = c(\"outer_split_num\")) |> \n  left_join(test_metrics_72, by = c(\"outer_split_num\")) |>\n  left_join(test_metrics_168, by = c(\"outer_split_num\")) |>\n  left_join(test_metrics_336, by = c(\"outer_split_num\")) |> \n  mutate(fold_num = rep(1:10, 3),\n         repeat_num = c(rep(1, 10), rep(2, 10), rep(3, 10))) |> \n  select(-outer_split_num) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 30\nColumns: 7\n$ lag0       <dbl> 0.8521426, 0.9194489, 0.9081365, 0.9305263, 0.8909992, 0.92…\n$ lag24      <dbl> 0.8411314, 0.9079732, 0.8948582, 0.9068800, 0.8607597, 0.89…\n$ lag72      <dbl> 0.8399275, 0.8938290, 0.9056717, 0.8659998, 0.8405634, 0.87…\n$ lag168     <dbl> 0.8037671, 0.8889850, 0.8692878, 0.8454601, 0.8108104, 0.87…\n$ lag336     <dbl> 0.8207671, 0.8782209, 0.8119466, 0.8438914, 0.7771305, 0.84…\n$ fold_num   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1…\n$ repeat_num <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n```\n\n\n:::\n:::\n\n\n\n\n#### Model evaluation\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| output: false\n\n# Repeated CV (id = repeat, id2 = fold within repeat)\n# with a common variance:  statistic ~ model + (model | id2/id)\nset.seed(101)\npp <- test_metrics_all |> \n  rename(id = fold_num,\n         id2 = repeat_num) |> \n  perf_mod(formula = statistic ~ model + (1 | id2/id),\n         transform = tidyposterior::logit_trans,  # for skewed & bounded AUC\n         iter = 4000, chains = 4, adapt_delta = .999, # increased iteration from 2000 to fix divergence issues\n         family = gaussian, \n)  \n```\n\n::: {.cell-output .cell-output-stdout .hidden}\n\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000909 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 9.09 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 1: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 1: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 1: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 1: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 1: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 1: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 1: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 1: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 1: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 1: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 1: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 5.889 seconds (Warm-up)\nChain 1:                5.06 seconds (Sampling)\nChain 1:                10.949 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 4.8e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.48 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 2: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 2: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 2: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 2: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 2: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 2: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 2: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 2: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 2: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 2: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 2: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 5.762 seconds (Warm-up)\nChain 2:                5.405 seconds (Sampling)\nChain 2:                11.167 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 3e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.3 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 3: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 3: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 3: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 3: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 3: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 3: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 3: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 3: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 3: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 3: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 3: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 7.327 seconds (Warm-up)\nChain 3:                5.076 seconds (Sampling)\nChain 3:                12.403 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 3.2e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 4: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 4: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 4: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 4: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 4: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 4: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 4: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 4: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 4: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 4: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 4: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 6.624 seconds (Warm-up)\nChain 4:                4.6 seconds (Sampling)\nChain 4:                11.224 seconds (Total)\nChain 4: \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: There were 2 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Examine the pairs() plot to diagnose sampling problems\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_tidy <- pp |> \n  tidy(seed = 123) \n\nq = c(.025, .5, .975)\npp_perf_tibble <- pp_tidy |> \n  group_by(model) |> \n  summarize(pp_median = quantile(posterior, probs = q[2]),\n            pp_lower = quantile(posterior, probs = q[1]), \n            pp_upper = quantile(posterior, probs = q[3])) |> \n  mutate(model = factor(model, levels = c(\"lag0\", \"lag24\", \"lag72\", \"lag168\", \"lag336\"),\n                        labels = c(\"0 lag\", \"24 lag\", \"72 lag\", \"168 lag\", \"336 lag\"))) |> \n  arrange(model)\n\npp_perf_tibble |> \n  write_csv(here::here(path_models_lag, \"pp_perf_tibble.csv\"))\n\npp_tidy |> \n  write_csv(here::here(path_models_lag, \"posteriors.csv\"))\n\npp_perf_tibble\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 4\n  model   pp_median pp_lower pp_upper\n  <fct>       <dbl>    <dbl>    <dbl>\n1 0 lag       0.901    0.884    0.916\n2 24 lag      0.881    0.861    0.899\n3 72 lag      0.869    0.847    0.889\n4 168 lag     0.858    0.835    0.880\n5 336 lag     0.837    0.811    0.862\n```\n\n\n:::\n:::\n\n\n\n\n\n### Model Comparisons\n\n#### Baseline Contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nci_baseline <- pp |>\n  contrast_models(list(\"lag0\", \"lag0\", \"lag0\", \"lag0\"), \n                  list(\"lag24\", \"lag72\", \"lag168\", \"lag336\")) |> \n  summary(size = 0) |> \n  mutate(contrast = factor(contrast, \n                           levels = c(\"lag0 vs lag24\", \"lag0 vs lag72\", \"lag0 vs lag168\", \n                                      \"lag0 vs lag336\"),\n                           labels = c(\"0 vs. 24\", \"0 vs. 72\", \n                                      \"0 vs. 168\", \"0 vs. 336\")))\n\nci_median_baseline <- pp |> \n  contrast_models(list(\"lag0\", \"lag0\", \"lag0\", \"lag0\"), \n                  list(\"lag24\", \"lag72\", \"lag168\", \"lag336\")) |>  \n  group_by(contrast) |> \n  summarize(median = quantile(difference, .5)) |> \n  mutate(contrast = factor(contrast, \n                           levels = c(\"lag0 vs. lag24\", \"lag0 vs. lag72\", \"lag0 vs. lag168\", \n                                      \"lag0 vs. lag336\"),\n                           labels = c(\"0 vs. 24\", \"0 vs. 72\", \n                                      \"0 vs. 168\", \"0 vs. 336\")))\n\n\nci_baseline <- ci_baseline |> \n  left_join(ci_median_baseline, by = c(\"contrast\")) \n\nci_baseline |> \n  write_csv(here::here(path_models_lag, \"contrast_baseline.csv\"))\n\nci_baseline\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 10\n  contrast  probability   mean  lower  upper  size pract_neg pract_equiv\n  <fct>           <dbl>  <dbl>  <dbl>  <dbl> <dbl>     <dbl>       <dbl>\n1 0 vs. 168           1 0.0427 0.0346 0.0514     0        NA          NA\n2 0 vs. 24            1 0.0199 0.0132 0.0268     0        NA          NA\n3 0 vs. 336           1 0.0638 0.0537 0.0741     0        NA          NA\n4 0 vs. 72            1 0.0322 0.0247 0.0402     0        NA          NA\n# ℹ 2 more variables: pract_pos <dbl>, median <dbl>\n```\n\n\n:::\n:::\n\n\n\n\n#### Adjacent Contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nci_lag <- pp |>\n  contrast_models(list(\"lag24\", \"lag72\", \"lag168\"), \n                  list(\"lag72\", \"lag168\", \"lag336\")) |> \n  summary(size = 0) |> \n  mutate(contrast = factor(contrast, \n                           levels = c(\"lag24 vs lag72\", \"lag72 vs lag168\", \n                                      \"lag168 vs lag336\"),\n                           labels = c(\"24 vs. 72\", \"72 vs. 168\", \"168 vs. 336\")))\n\nci_median_lag <- pp |> \n  contrast_models(list(\"lag24\", \"lag72\", \"lag168\"), \n                  list(\"lag72\", \"lag168\", \"lag336\")) |>  \n  group_by(contrast) |> \n  summarize(median = quantile(difference, .5)) |> \n  mutate(contrast = factor(contrast, \n                           levels = c(\"lag24 vs. lag72\", \"lag72 vs. lag168\", \n                                      \"lag168 vs. lag336\"),\n                           labels = c(\"24 vs. 72\", \"72 vs. 168\", \"168 vs. 336\")))\n\nci_lag <- ci_lag |> \n  left_join(ci_median_lag, by = c(\"contrast\")) |> \n  arrange(contrast)\n\nci_lag |> \n  write_csv(here::here(path_models_lag, \"contrast_adjacent.csv\"))\n\nci_lag\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 10\n  contrast    probability   mean   lower  upper  size pract_neg pract_equiv\n  <fct>             <dbl>  <dbl>   <dbl>  <dbl> <dbl>     <dbl>       <dbl>\n1 24 vs. 72         0.998 0.0123 0.00531 0.0196     0        NA          NA\n2 72 vs. 168        0.986 0.0105 0.00288 0.0182     0        NA          NA\n3 168 vs. 336       1     0.0211 0.0122  0.0300     0        NA          NA\n# ℹ 2 more variables: pract_pos <dbl>, median <dbl>\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}