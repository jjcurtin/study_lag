---
title: "Evaluate `r params$model` models' performance in held out outer folds for `r params$window` and lead = `r params$lead` and `r params$version`"
author: "John Curtin & Kendra Wyant"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
format:
  html:
    embed-resources: true
params:
  study: "lag"
  cv: "nested"
  window: "1week"
  model: "main" # Note this should always be "main" - baseline models have separate outer script
  lead: 336
  version: "v1"
editor_options: 
  chunk_output_type: console
---

### Code Status

In use with iterative improvement

### Notes
This is a generic script that reproduces the CV metrics for the best model configuration, calculates various performance metrics from that resampling, makes plots, and then fits the best config to the final sample to do feature importance.

This script is called by various studies, passing in the data_type, window, lead, and version.


### Set Up Environment

```{r}
study <- params$study
cv <- params$cv
window <- params$window
model <- params$model
lead <- params$lead 
version <- params$version
```

Function conflicts
```{r, packages_workflow}
#| message: false
#| warning: false

# handle conflicts
options(conflicts.policy = "depends.ok")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true")
tidymodels_conflictRules()
```

Packages for script
```{r, packages_script}
#| message: false
#| warning: false

library(tidyverse)
library(tidymodels)
library(tidyposterior)
# library(SHAPforxgboost)
# library(rstanarm)

theme_set(theme_classic()) 
```

Source support functions
```{r source_functions}
# EDA
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true")
# CHTC support functions
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/chtc/static_files/fun_chtc.R?raw=true")
```


Absolute paths
```{r, absolute_paths}
path_processed <- format_path(str_c("studydata/risk/data_processed/", study))
path_input <- format_path(str_c("studydata/risk/chtc/", study))
path_models <- format_path(str_c("studydata/risk/models/", study))
```


Chunk Defaults
```{r defaults}
#| include: false

knitr::opts_chunk$set(attr.output='style="max-height: 500px;"')

options(tibble.width = Inf)
options(tibble.print_max = Inf)
```


### Model Performance Metrics

```{r read_metrics_preds}
preds_out <- read_rds(here::here(path_models, str_c("outer_preds_", window, "_", 
                                                    lead, "_", version, "_", 
                                                    cv, "_", model, ".rds")))
metrics_out <- read_rds(here::here(path_models, str_c("outer_metrics_", window, "_", 
                                                      lead, "_", version, "_", 
                                                    cv, "_", model, ".rds")))
```

#### Inner AUC

Best model configurations were selected using the median AUCs across 10 inner folds.  30 (3x10) models were selected.  

This comes from metrics_out validation sets.  Only used for auROC in validation sets

```{r}
metrics_out |> glimpse()

metrics_out |> 
  summarize(median(roc_auc_in), mean(roc_auc_in), min(roc_auc_in), max(roc_auc_in), sd(roc_auc_in))
```


#### Final Test/Outer Metrics

This calculates auROC and other metrics using test sets (out loop held out folds).  The metrics also use probability corrected (prob_beta) probabilities.

First get auROCs 
```{r}
auroc <- preds_out %>%
  nest(.by = outer_split_num, .key = "preds") |> 
  mutate(auroc = map(preds, \(preds) roc_auc(preds, prob_beta, 
                                             truth = label))) |> 
  select(-preds) |> 
  unnest(auroc) |> 
  select(-.estimator)
```

And then secondary metrics
```{r}
# function to get  other metrics at Youdens j
get_other_metrics <- function(preds) {
  
  j_thres <- preds |>  
    roc_curve(prob_beta, truth = label) |> 
    mutate(j = sensitivity + specificity - 1) |>
    slice_max(j) |>
    pull(.threshold)
  
  split_num <- preds |> 
    pull(outer_split_num) |> 
    head(1)  
  
  preds |>
    mutate(estimate = if_else(prob_beta > j_thres, "Lapse", "No lapse"),
           estimate = factor(estimate, levels = c("Lapse", "No lapse"))) |>
    conf_mat(truth = label, estimate = estimate) |>
    summary() |>
    select(-.estimator) |>
    filter(.metric %in% c("sens", "spec", "ppv", "npv", "bal_accuracy")) |>
    mutate(outer_split_num = split_num) |> 
    relocate(outer_split_num, .metric, .estimate)
}

other_metrics <- preds_out |>  
  mutate(split_num = outer_split_num) |> # need to have it in preds
  nest(.by = split_num, .key = "preds") |> 
  mutate(metrics = map(preds, \(preds) get_other_metrics(preds))) |>  
  select(-preds) |> 
  unnest(metrics) |> 
  select(-split_num)
```

Bind and save
```{r}
metrics_test <- auroc |> 
  bind_rows(other_metrics) |>
  arrange(outer_split_num) |> 
  write_csv(here::here(path_models, str_c("test_metrics_", window, "_", 
                                                      lead, "_", version, "_", 
                                                      cv, ".csv")))  
```

Median metric stats
```{r}
metrics_test |> 
  group_by(.metric) |> 
  summarize(median = median(.estimate), IQR = IQR(.estimate))
```

Mean metric stats
```{r}
metrics_test |> 
  group_by(.metric) |> 
  summarize(mean = mean(.estimate), sd = sd(.estimate))
```

Table for each outer fold
```{r metrics_out_kbl}
metrics_test |>
  pivot_wider(names_from = .metric,
              values_from = .estimate) |> 
  print_kbl()
```

#### ROC curve
- This is single ROC by concatenating all outer folds.
- Could consider reporting this AUC though likely median/mean of outer fold AUCs is more appropriate
-Could also plot ROC by fold but maybe too confusing?
```{r roc_info}
preds_out %>%
  roc_auc(prob_beta, truth = label)

roc_data <- preds_out %>% 
  roc_curve(prob_beta, truth = label)
  
roc_data %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity, color = .threshold)) +
  geom_path(linewidth = 2) +
  geom_abline(lty = 3) +
  coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) +
  labs(x = "Specificity",
       y = "Sensitivity") +
  scale_x_continuous(breaks = seq(0,1,.25),
    labels = sprintf("%.2f", seq(1,0,-.25))) +
  scale_color_gradient(low="blue", high="red") +
  theme(axis.text = element_text(size = rel(1.50)), 
        axis.title = element_text(size = rel(1.75)))
```

And these are the curves for each outer fold
```{r}
# rocs per fold
roc_folds <- preds_out %>%
  nest(.by = outer_split_num, .key = "preds") |> 
  mutate(roc = map(preds, \(preds) roc_curve(preds, prob_beta, 
                                             truth = label)))

fig_roc_folds <- roc_data %>%  # plot region from full concatenated data 
  ggplot(aes(x = 1 - specificity, y = sensitivity)) + 
  geom_abline(lty = 3) +
  coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) +
  labs(x = "Specificity",
       y = "Sensitivity") +
  scale_x_continuous(breaks = seq(0,1,.25),
    labels = sprintf("%.2f", seq(1,0,-.25))) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
  
for (i in 1:nrow(roc_folds)) {
  fig_roc_folds <- fig_roc_folds +
     geom_path(data = roc_folds$roc[[i]],
               mapping = aes(x = 1 - specificity, y = sensitivity),
               color = "gray")
}

#add full concatenated curve
fig_roc_folds +
     geom_path(data = roc_data,
               mapping = aes(x = 1 - specificity, y = sensitivity, color = .threshold),
               linewidth = 2) +
    scale_color_gradient(low="blue", high="red")
```

#### Plot histogram of auROC test folds
```{r plot_outer}
metrics_test |> 
  filter(.metric == "roc_auc") |> 
  ggplot(aes(x = .estimate)) +
  geom_histogram(bins = 10) +
  xlab("auROC")
```

#### Probability Histograms
Histograms with free Y. Remove `scales = "free_y"` for fixed y but doesnt make sense to do this with the class imbalance
```{r prob_plot_free}
preds_out %>% 
  ggplot(data = ., aes(x = prob_beta)) + 
   geom_histogram(bins = 100, fill = "white", col = "black") +
   facet_wrap(~label, nrow = 2, scales = "free_y") +
   xlab("Pr(Lapse)") +
  theme(axis.text = element_text(size = rel(1.00)), 
        axis.title.x = element_text(size = rel(1.25)),
        strip.text = element_text(size = rel(1.75)))
```


#### Confusion matrices based on concatenated test folds

Confusion matrix using .5 threshold
```{r default_cm}
(cm <- preds_out |> 
   mutate(estimate = if_else(prob_beta > .5, "Lapse", "No lapse"),
          estimate = factor(estimate, levels = c("Lapse", "No lapse"))) |> 
   conf_mat(truth = label, estimate = estimate))

cm %>% 
  autoplot() +
  theme(axis.text = element_text(size = rel(1.50)), 
        axis.title = element_text(size = rel(1.75)))

cm %>% summary()

# save plot for presentations
# ggsave(file.choose(), width = 7.5, height = 6.5, units = "in", device = "png",  dpi = 100)
```


Confusion matrix at optimal cut-point (based on Youdens J index)

https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1444894/
https://pubmed.ncbi.nlm.nih.gov/15405679/

```{r youden_cm}
j_thres_roc <- roc_data |> 
  mutate(j = sensitivity + specificity - 1) |> 
  slice_max(j) |> 
  print() |> 
  pull(.threshold)

(cm <- preds_out |> 
   mutate(estimate = if_else(prob_beta > j_thres_roc, "Lapse", "No lapse"),
          estimate = factor(estimate, levels = c("Lapse", "No lapse"))) |> 
   conf_mat(truth = label, estimate = estimate))

cm %>% 
  autoplot() +
  theme(axis.text = element_text(size = rel(1.50)), 
        axis.title = element_text(size = rel(1.75)))

cm %>% summary()
```

#### PR Curve
Here is precision/recall by concatenating all folds.  Same approach as above for ROC
```{r pr_info}
preds_out %>%
  pr_auc(prob_beta, truth = label)

pr_data <- preds_out %>% 
  pr_curve(prob_beta, truth = label)

pr_data %>% 
  ggplot(aes(x = recall, y = precision, color = .threshold)) +
  geom_path(linewidth = 2) +
  geom_hline(lty = 3, yintercept = mean(preds_out$label == "Lapse")) +
  coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) +
  scale_color_gradient(low="blue", high="red") +
  labs(x = "Recall (Sensitivity)",
       y = "Precision (PPV)")
```

Sensitivity at min PPV of .7
```{r}
pr_data |> 
  filter(precision >= .7) |> 
  arrange(desc(recall)) |> 
  slice(1) |> 
  print()
```

Sensitivity at best F
```{r}
f <- pr_data |> 
  mutate(f =  (2 * precision * recall) / (precision + recall)) |> 
  slice_max(f) |> 
  print()
```


### Feature Importance

#### Grouped Features

```{r read_shaps_grp}
shapsgrp_out <- readRDS(here::here(path_models, str_c("outer_shapsgrp_",
                                                      window, "_", lead, "_",
                                                      version, "_", cv, "_",
                                                      model, ".rds")))
```


Global importance SHAP plot for grouped features
```{r shap_grouped_plot}
shapsgrp_out %>%
  group_by(variable_grp) %>%
  summarize(mean_value = mean(abs(value)), .groups = "drop") %>%
  arrange(mean_value) %>%
  mutate(variable_grp = factor(variable_grp),
         variable_grp = fct_inorder(variable_grp)) %>%
  ggplot(mapping = aes(x = variable_grp, y = mean_value)) +
  geom_point(size = 2, color = "red") +
  geom_segment(aes(x = variable_grp, y = mean_value, xend = variable_grp),
               yend = 0, colour = "grey50")  +
  ylab("Mean |SHAP| value") +
  coord_flip()
```
